-- this file tests the hyperparameters for MSE criterion based first layer auto encoder
-- nested grid searching
-- set parameters for hyper-experiments


require 'factornnMSE'
require 'torch'
require 'hypero'
-- torch.manualSeed()
-- hyper parameters settings for training factor model
hopt = {            
   batchSize = 100,
   maxNumEpoch = 150,
   LR = 2e-5,       -- bigger range for SGD and RMSprop method
   
   optimMethod = 'ADAM',             --probabilities for selecting those values  'SGD','ADAM','RMSprop'
   numHiddenUnits =2400,--    2400,  -- { 2, 3, 3, 2},     --probabilities for selecting those values 800, 1000, 1200, 1500 
   numHiddenUnits_VT= 1600,
   marginVT =torch.Tensor({38,40}),
   hingeCoef ={0.01,0.05,0.1},
   noiseType = {'Gaussian','masking'},                   -- Gaussian noise and masking noise
   GaussianCorruptionVar = {0.001,0.005,0.01,0.05},
   maskCorruptionVar ={0.1,0.15,0.25,0.4},  -- 2.5,2.5,2.5,2.5 {0.1, 0.15, 0.25, 0.4}
   momentum = 0.9,
   weightDecay = 0.0001,
   sampleEachEpoch = 20000,          -- 10000, 20000, 40000
   RMSalpha =0.9,
   coefL1 = 0,                   -- L1 and L2 penalty coefficient for weight matrix
   coefL2 = 0.0001,
   cuda = true
   }

-- no evaluations


print('<Hyper optimization for MSE based first layer has begin.\n')
for j=1,hopt.marginVT:size(1) do
   for k=1, #hopt.hingeCoef do
      for nt=1, #hopt.noiseType do
	 for nc =1,#hopt.maskCorruptionVar do
	    
	    local opt = _.clone(hopt)

	    -- set hyper parameters for training factor model
	    local hp = {}

	    hp.batchSize =  opt.batchSize
	    hp.learningRate =  opt.LR
	    hp.optimMethod = opt.optimMethod
	    hp.numHiddenUnits = opt.numHiddenUnits
	    hp.numHiddenUnits_VT = opt.numHiddenUnits_VT 
	    hp.marginVT = opt.marginVT[j]
	    hp.hingeCoef = opt.hingeCoef[k]
	    -- only one type of noise can be used
	    hp.noiseType = opt.noiseType[nt]
	    if hp.noiseType == 'Gaussian' then
	       hp.GaussianCorruptionVar = opt.GaussianCorruptionVar[nc]
	       hp.maskCorruptionVar = 0
	    else
	       hp.maskCorruptionVar = opt.maskCorruptionVar[nc]
	       hp.GaussianCorruptionVar = 0
	    end
	    hp.momentum = opt.momentum
	    hp.weightDecay = opt.weightDecay
	    hp.sampleEachEpoch = opt.sampleEachEpoch
	    hp.maxNumEpoch = opt.maxNumEpoch
	    hp.maxIter = opt.maxIter
	    hp.RMSalpha = opt.RMSalpha
	    hp.coefL1 = opt.coefL1
	    hp.coefL2 = opt.coefL2
	    hp.cuda = opt.cuda
	    
	    -- -- train the factor model with above hyper-parameters
	    factornnMSE.train(hp,j,k,nt,nc)
	    
	    collectgarbage()
	 end
      end
   end
end


print('<Hyper optimization for MSE based first layer has finished.\n')
      
   
