
-- this file opens the saved opts and lossFun/accuracy track,
-- show the parameters, and plot the track data

require 'torch'
require 'nn'
require 'xlua'
require 'optim'
require 'gnuplot'
require 'cunn'


os.execute('killall gnuplot')
--i,j,k,nt,nc = 2,2,1,1,2
--hyperExperName = '/home/mark/Documents/VT_learning/Logs/logMES/hexLog_i'.. tostring(i)..'j'..tostring(j)..'k'..tostring(k)..'nt'..tostring(nt)..'nc'..tostring(nc)
-- 1,3,1,3
j,k,nt,nc=1,2,1,3

hyperExperName = '/home/mark/Documents/VT_learning/Logs/squarePAlayer2/MES_'..'j'..tostring(j)..'k'..tostring(k)..'nt'..tostring(nt)..'nc'..tostring(nc)

--hyperExperName = '/media/usb/log/MES/MES_'..'j'..tostring(j)..'k'..tostring(k)..'nt'..tostring(nt)..'nc'..tostring(nc)
optFactor = torch.load(hyperExperName.."/hypers.t7")

print("optFactor is: ")
print(optFactor)



-- compute the statistics for evaluating margin parameters

qrsData = torch.load('/home/mark/Documents/VT_learning/squarePA/firstLayer/candidates/qrsLayer1.t7')
--   qrsData = torch.load('/home/mark/Documents/VT_learning/data/qrsDataNormalized.t7')

cond_VT = torch.load(hyperExperName..'/cond_VT.net')
cond_PA = torch.load(hyperExperName..'/cond_PA.net')


flowNet = nn.ConcatTable():add(cond_VT:get(1):get(1):get(1)):add(cond_PA:get(1):get(1):get(1) )

train_nodes = flowNet:forward(qrsData.train_x)


numSamplesForMargin = 4000
margin_index= torch.randperm(train_nodes[1]:size(1))[{{1,2*numSamplesForMargin}}]
margin_vt_pair1 = torch.Tensor(numSamplesForMargin, train_nodes[1]:size(2)):cuda()
margin_vt_pair2 = torch.Tensor(numSamplesForMargin, train_nodes[1]:size(2)):cuda()
margin_pa_pair1 = torch.Tensor(numSamplesForMargin, train_nodes[2]:size(2)):cuda()
margin_pa_pair2 = torch.Tensor(numSamplesForMargin, train_nodes[2]:size(2)):cuda()

for i=1,numSamplesForMargin do
   margin_vt_pair1[i] = train_nodes[1][margin_index[i]]
   margin_vt_pair2[i] = train_nodes[1][margin_index[i+numSamplesForMargin]]
   margin_pa_pair1[i] = train_nodes[2][margin_index[i]]
   margin_pa_pair2[i] = train_nodes[2][margin_index[i+numSamplesForMargin]]
end
vt_distance = torch.sqrt(torch.norm(margin_vt_pair1 - margin_vt_pair2,2)^2/numSamplesForMargin)
pa_distance = torch.sqrt(torch.norm(margin_pa_pair1 - margin_pa_pair2,2)^2/numSamplesForMargin)

print("Average VT distance is "..tostring(vt_distance))
print("Average PA distance is "..tostring(pa_distance))
lossFactor_vt = torch.load(hyperExperName.."/cond_lossFun_vt.t7")



lossEval = torch.load(hyperExperName.."/classifyTrack.t7")
print('The best loss for full nodes is '..tostring(torch.min(lossEval.lossVal)))
print('The best distance for full nodes is '..tostring(torch.min(lossEval.mserVal)))
--plot them
gnuplot.figure(1)
gnuplot.title('Factor Loss function minimization over epochs')
gnuplot.plot(lossFactor_vt)   
gnuplot.xlabel('epochs')
gnuplot.ylabel('L(x)')


-- plot the accuracy function track
gnuplot.figure(2)
gnuplot.title('Classification loss function minimization over epochs for full nodes')
gnuplot.plot({'Training',lossEval.lossTrain,'-'}, {'Validation',lossEval.lossVal,'-'})   
gnuplot.xlabel('epochs')
gnuplot.ylabel('L(x)')



gnuplot.figure(3)
gnuplot.title('Geodestic distance minimization over epochs for full nodes')
gnuplot.plot({'Training',lossEval.mserTrain,'-'}, {'Validation',lossEval.mserVal,'-'})   
gnuplot.xlabel('epochs')
gnuplot.ylabel('L(x)')
